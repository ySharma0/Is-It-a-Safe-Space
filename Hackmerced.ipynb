{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eight-track",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Denylson\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Denylson\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Denylson\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import sent_tokenize \n",
    "from nltk import word_tokenize\n",
    "from nltk import PorterStemmer\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "#ML models, and other tools\n",
    "import torch as torch\n",
    "from torch import nn as nn\n",
    "import keras as keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "royal-information",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "#     df['tweet_token'],\n",
    "#     df['class'],\n",
    "#     test_size = 0.2,\n",
    "#     random_state = 10,\n",
    "#     stratify=df['class'].values,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "supreme-watts",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " ',',\n",
       " '.',\n",
       " 'of',\n",
       " 'to',\n",
       " 'and',\n",
       " 'in',\n",
       " 'a',\n",
       " '\"',\n",
       " \"'s\",\n",
       " 'for',\n",
       " '-',\n",
       " 'that',\n",
       " 'on',\n",
       " 'is',\n",
       " 'was',\n",
       " 'said',\n",
       " 'with',\n",
       " 'he',\n",
       " 'as',\n",
       " 'it',\n",
       " 'by',\n",
       " 'at',\n",
       " '(',\n",
       " ')',\n",
       " 'from',\n",
       " 'his',\n",
       " \"''\",\n",
       " '``',\n",
       " 'an',\n",
       " 'be',\n",
       " 'has',\n",
       " 'are',\n",
       " 'have',\n",
       " 'but',\n",
       " 'were',\n",
       " 'not',\n",
       " 'this',\n",
       " 'who',\n",
       " 'they',\n",
       " 'had',\n",
       " 'i',\n",
       " 'which',\n",
       " 'will',\n",
       " 'their',\n",
       " ':',\n",
       " 'or',\n",
       " 'its',\n",
       " 'one',\n",
       " 'after',\n",
       " 'new',\n",
       " 'been',\n",
       " 'also',\n",
       " 'we',\n",
       " 'would',\n",
       " 'two',\n",
       " 'more',\n",
       " \"'\",\n",
       " 'first',\n",
       " 'about',\n",
       " 'up',\n",
       " 'when',\n",
       " 'year',\n",
       " 'there',\n",
       " 'all',\n",
       " '--',\n",
       " 'out',\n",
       " 'she',\n",
       " 'other',\n",
       " 'people',\n",
       " \"n't\",\n",
       " 'her',\n",
       " 'percent',\n",
       " 'than',\n",
       " 'over',\n",
       " 'into',\n",
       " 'last',\n",
       " 'some',\n",
       " 'government',\n",
       " 'time',\n",
       " '$',\n",
       " 'you',\n",
       " 'years',\n",
       " 'if',\n",
       " 'no',\n",
       " 'world',\n",
       " 'can',\n",
       " 'three',\n",
       " 'do',\n",
       " ';',\n",
       " 'president',\n",
       " 'only',\n",
       " 'state',\n",
       " 'million',\n",
       " 'could',\n",
       " 'us',\n",
       " 'most',\n",
       " '_',\n",
       " 'against',\n",
       " 'u.s.',\n",
       " 'so',\n",
       " 'them',\n",
       " 'what',\n",
       " 'him',\n",
       " 'united',\n",
       " 'during',\n",
       " 'before',\n",
       " 'may',\n",
       " 'since',\n",
       " 'many',\n",
       " 'while',\n",
       " 'where',\n",
       " 'states',\n",
       " 'because',\n",
       " 'now',\n",
       " 'city',\n",
       " 'made',\n",
       " 'like',\n",
       " 'between',\n",
       " 'did',\n",
       " 'just',\n",
       " 'national',\n",
       " 'day',\n",
       " 'country',\n",
       " 'under',\n",
       " 'such',\n",
       " 'second',\n",
       " 'then',\n",
       " 'company',\n",
       " 'group',\n",
       " 'any',\n",
       " 'through',\n",
       " 'china',\n",
       " 'four',\n",
       " 'being',\n",
       " 'down',\n",
       " 'war',\n",
       " 'back',\n",
       " 'off',\n",
       " 'south',\n",
       " 'american',\n",
       " 'minister',\n",
       " 'police',\n",
       " 'well',\n",
       " 'including',\n",
       " 'team',\n",
       " 'international',\n",
       " 'week',\n",
       " 'officials',\n",
       " 'still',\n",
       " 'both',\n",
       " 'even',\n",
       " 'high',\n",
       " 'part',\n",
       " 'told',\n",
       " 'those',\n",
       " 'end',\n",
       " 'former',\n",
       " 'these',\n",
       " 'make',\n",
       " 'billion',\n",
       " 'work',\n",
       " 'our',\n",
       " 'home',\n",
       " 'school',\n",
       " 'party',\n",
       " 'house',\n",
       " 'old',\n",
       " 'later',\n",
       " 'get',\n",
       " 'another',\n",
       " 'tuesday',\n",
       " 'news',\n",
       " 'long',\n",
       " 'five',\n",
       " 'called',\n",
       " '1',\n",
       " 'wednesday',\n",
       " 'military',\n",
       " 'way',\n",
       " 'used',\n",
       " 'much',\n",
       " 'next',\n",
       " 'monday',\n",
       " 'thursday',\n",
       " 'friday',\n",
       " 'game',\n",
       " 'here',\n",
       " '?',\n",
       " 'should',\n",
       " 'take',\n",
       " 'very',\n",
       " 'my',\n",
       " 'north',\n",
       " 'security',\n",
       " 'season',\n",
       " 'york',\n",
       " 'how',\n",
       " 'public',\n",
       " 'early',\n",
       " 'according',\n",
       " 'several',\n",
       " 'court',\n",
       " 'say',\n",
       " 'around',\n",
       " 'foreign',\n",
       " '10',\n",
       " 'until',\n",
       " 'set',\n",
       " 'political',\n",
       " 'says',\n",
       " 'market',\n",
       " 'however',\n",
       " 'family',\n",
       " 'life',\n",
       " 'same',\n",
       " 'general',\n",
       " '–',\n",
       " 'left',\n",
       " 'good',\n",
       " 'top',\n",
       " 'university',\n",
       " 'going',\n",
       " 'number',\n",
       " 'major',\n",
       " 'known',\n",
       " 'points',\n",
       " 'won',\n",
       " 'six',\n",
       " 'month',\n",
       " 'dollars',\n",
       " 'bank',\n",
       " '2',\n",
       " 'iraq',\n",
       " 'use',\n",
       " 'members',\n",
       " 'each',\n",
       " 'area',\n",
       " 'found',\n",
       " 'official',\n",
       " 'sunday',\n",
       " 'place',\n",
       " 'go',\n",
       " 'based',\n",
       " 'among',\n",
       " 'third',\n",
       " 'times',\n",
       " 'took',\n",
       " 'right',\n",
       " 'days',\n",
       " 'local',\n",
       " 'economic',\n",
       " 'countries',\n",
       " 'see',\n",
       " 'best',\n",
       " 'report',\n",
       " 'killed',\n",
       " 'held',\n",
       " 'business',\n",
       " 'west',\n",
       " 'does',\n",
       " 'own',\n",
       " '%',\n",
       " 'came',\n",
       " 'law',\n",
       " 'months',\n",
       " 'women',\n",
       " \"'re\",\n",
       " 'power',\n",
       " 'think',\n",
       " 'service',\n",
       " 'children',\n",
       " 'bush',\n",
       " 'show',\n",
       " '/',\n",
       " 'help',\n",
       " 'chief',\n",
       " 'saturday',\n",
       " 'system',\n",
       " 'john',\n",
       " 'support',\n",
       " 'series',\n",
       " 'play',\n",
       " 'office',\n",
       " 'following',\n",
       " 'me',\n",
       " 'meeting',\n",
       " 'expected',\n",
       " 'late',\n",
       " 'washington',\n",
       " 'games',\n",
       " 'european',\n",
       " 'league',\n",
       " 'reported',\n",
       " 'final',\n",
       " 'added',\n",
       " 'without',\n",
       " 'british',\n",
       " 'white',\n",
       " 'history',\n",
       " 'man',\n",
       " 'men',\n",
       " 'became',\n",
       " 'want',\n",
       " 'march',\n",
       " 'case',\n",
       " 'few',\n",
       " 'run',\n",
       " 'money',\n",
       " 'began',\n",
       " 'open',\n",
       " 'name',\n",
       " 'trade',\n",
       " 'center',\n",
       " '3',\n",
       " 'israel',\n",
       " 'oil',\n",
       " 'too',\n",
       " 'al',\n",
       " 'film',\n",
       " 'win',\n",
       " 'led',\n",
       " 'east',\n",
       " 'central',\n",
       " '20',\n",
       " 'air',\n",
       " 'come',\n",
       " 'chinese',\n",
       " 'town',\n",
       " 'leader',\n",
       " 'army',\n",
       " 'line',\n",
       " 'never',\n",
       " 'little',\n",
       " 'played',\n",
       " 'prime',\n",
       " 'death',\n",
       " 'companies',\n",
       " 'least',\n",
       " 'put',\n",
       " 'forces',\n",
       " 'past',\n",
       " 'de',\n",
       " 'half',\n",
       " 'june',\n",
       " 'saying',\n",
       " 'know',\n",
       " 'federal',\n",
       " 'french',\n",
       " 'peace',\n",
       " 'earlier',\n",
       " 'capital',\n",
       " 'force',\n",
       " 'great',\n",
       " 'union',\n",
       " 'near',\n",
       " 'released',\n",
       " 'small',\n",
       " 'department',\n",
       " 'every',\n",
       " 'health',\n",
       " 'japan',\n",
       " 'head',\n",
       " 'ago',\n",
       " 'night',\n",
       " 'big',\n",
       " 'cup',\n",
       " 'election',\n",
       " 'region',\n",
       " 'director',\n",
       " 'talks',\n",
       " 'program',\n",
       " 'far',\n",
       " 'today',\n",
       " 'statement',\n",
       " 'july',\n",
       " 'although',\n",
       " 'district',\n",
       " 'again',\n",
       " 'born',\n",
       " 'development',\n",
       " 'leaders',\n",
       " 'council',\n",
       " 'close',\n",
       " 'record',\n",
       " 'along',\n",
       " 'county',\n",
       " 'france',\n",
       " 'went',\n",
       " 'point',\n",
       " 'must',\n",
       " 'spokesman',\n",
       " 'your',\n",
       " 'member',\n",
       " 'plan',\n",
       " 'financial',\n",
       " 'april',\n",
       " 'recent',\n",
       " 'campaign',\n",
       " 'become',\n",
       " 'troops',\n",
       " 'whether',\n",
       " 'lost',\n",
       " 'music',\n",
       " '15',\n",
       " 'got',\n",
       " 'israeli',\n",
       " '30',\n",
       " 'need',\n",
       " '4',\n",
       " 'lead',\n",
       " 'already',\n",
       " 'russia',\n",
       " 'though',\n",
       " 'might',\n",
       " 'free',\n",
       " 'hit',\n",
       " 'rights',\n",
       " '11',\n",
       " 'information',\n",
       " 'away',\n",
       " '12',\n",
       " '5',\n",
       " 'others',\n",
       " 'control',\n",
       " 'within',\n",
       " 'large',\n",
       " 'economy',\n",
       " 'press',\n",
       " 'agency',\n",
       " 'water',\n",
       " 'died',\n",
       " 'career',\n",
       " 'making',\n",
       " '...',\n",
       " 'deal',\n",
       " 'attack',\n",
       " 'side',\n",
       " 'seven',\n",
       " 'better',\n",
       " 'less',\n",
       " 'september',\n",
       " 'once',\n",
       " 'clinton',\n",
       " 'main',\n",
       " 'due',\n",
       " 'committee',\n",
       " 'building',\n",
       " 'conference',\n",
       " 'club',\n",
       " 'january',\n",
       " 'decision',\n",
       " 'stock',\n",
       " 'america',\n",
       " 'given',\n",
       " 'give',\n",
       " 'often',\n",
       " 'announced',\n",
       " 'television',\n",
       " 'industry',\n",
       " 'order',\n",
       " 'young',\n",
       " \"'ve\",\n",
       " 'palestinian',\n",
       " 'age',\n",
       " 'start',\n",
       " 'administration',\n",
       " 'russian',\n",
       " 'prices',\n",
       " 'round',\n",
       " 'december',\n",
       " 'nations',\n",
       " \"'m\",\n",
       " 'human',\n",
       " 'india',\n",
       " 'defense',\n",
       " 'asked',\n",
       " 'total',\n",
       " 'october',\n",
       " 'players',\n",
       " 'bill',\n",
       " 'important',\n",
       " 'southern',\n",
       " 'move',\n",
       " 'fire',\n",
       " 'population',\n",
       " 'rose',\n",
       " 'november',\n",
       " 'include',\n",
       " 'further',\n",
       " 'nuclear',\n",
       " 'street',\n",
       " 'taken',\n",
       " 'media',\n",
       " 'different',\n",
       " 'issue',\n",
       " 'received',\n",
       " 'secretary',\n",
       " 'return',\n",
       " 'college',\n",
       " 'working',\n",
       " 'community',\n",
       " 'eight',\n",
       " 'groups',\n",
       " 'despite',\n",
       " 'level',\n",
       " 'largest',\n",
       " 'whose',\n",
       " 'attacks',\n",
       " 'germany',\n",
       " 'august',\n",
       " 'change',\n",
       " 'church',\n",
       " 'nation',\n",
       " 'german',\n",
       " 'station',\n",
       " 'london',\n",
       " 'weeks',\n",
       " 'having',\n",
       " '18',\n",
       " 'research',\n",
       " 'black',\n",
       " 'services',\n",
       " 'story',\n",
       " '6',\n",
       " 'europe',\n",
       " 'sales',\n",
       " 'policy',\n",
       " 'visit',\n",
       " 'northern',\n",
       " 'lot',\n",
       " 'across',\n",
       " 'per',\n",
       " 'current',\n",
       " 'board',\n",
       " 'football',\n",
       " 'ministry',\n",
       " 'workers',\n",
       " 'vote',\n",
       " 'book',\n",
       " 'fell',\n",
       " 'seen',\n",
       " 'role',\n",
       " 'students',\n",
       " 'shares',\n",
       " 'iran',\n",
       " 'process',\n",
       " 'agreement',\n",
       " 'quarter',\n",
       " 'full',\n",
       " 'match',\n",
       " 'started',\n",
       " 'growth',\n",
       " 'yet',\n",
       " 'moved',\n",
       " 'possible',\n",
       " 'western',\n",
       " 'special',\n",
       " '100',\n",
       " 'plans',\n",
       " 'interest',\n",
       " 'behind',\n",
       " 'strong',\n",
       " 'england',\n",
       " 'named',\n",
       " 'food',\n",
       " 'period',\n",
       " 'real',\n",
       " 'authorities',\n",
       " 'car',\n",
       " 'term',\n",
       " 'rate',\n",
       " 'race',\n",
       " 'nearly',\n",
       " 'korea',\n",
       " 'enough',\n",
       " 'site',\n",
       " 'opposition',\n",
       " 'keep',\n",
       " '25',\n",
       " 'call',\n",
       " 'future',\n",
       " 'taking',\n",
       " 'island',\n",
       " '2008',\n",
       " '2006',\n",
       " 'road',\n",
       " 'outside',\n",
       " 'really',\n",
       " 'century',\n",
       " 'democratic',\n",
       " 'almost',\n",
       " 'single',\n",
       " 'share',\n",
       " 'leading',\n",
       " 'trying',\n",
       " 'find',\n",
       " 'album',\n",
       " 'senior',\n",
       " 'minutes',\n",
       " 'together',\n",
       " 'congress',\n",
       " 'index',\n",
       " 'australia',\n",
       " 'results',\n",
       " 'hard',\n",
       " 'hours',\n",
       " 'land',\n",
       " 'action',\n",
       " 'higher',\n",
       " 'field',\n",
       " 'cut',\n",
       " 'coach',\n",
       " 'elections',\n",
       " 'san',\n",
       " 'issues',\n",
       " 'executive',\n",
       " 'february',\n",
       " 'production',\n",
       " 'areas',\n",
       " 'river',\n",
       " 'face',\n",
       " 'using',\n",
       " 'japanese',\n",
       " 'province',\n",
       " 'park',\n",
       " 'price',\n",
       " 'commission',\n",
       " 'california',\n",
       " 'father',\n",
       " 'son',\n",
       " 'education',\n",
       " '7',\n",
       " 'village',\n",
       " 'energy',\n",
       " 'shot',\n",
       " 'short',\n",
       " 'africa',\n",
       " 'key',\n",
       " 'red',\n",
       " 'association',\n",
       " 'average',\n",
       " 'pay',\n",
       " 'exchange',\n",
       " 'eu',\n",
       " 'something',\n",
       " 'gave',\n",
       " 'likely',\n",
       " 'player',\n",
       " 'george',\n",
       " '2007',\n",
       " 'victory',\n",
       " '8',\n",
       " 'low',\n",
       " 'things',\n",
       " '2010',\n",
       " 'pakistan',\n",
       " '14',\n",
       " 'post',\n",
       " 'social',\n",
       " 'continue',\n",
       " 'ever',\n",
       " 'look',\n",
       " 'chairman',\n",
       " 'job',\n",
       " '2000',\n",
       " 'soldiers',\n",
       " 'able',\n",
       " 'parliament',\n",
       " 'front',\n",
       " 'himself',\n",
       " 'problems',\n",
       " 'private',\n",
       " 'lower',\n",
       " 'list',\n",
       " 'built',\n",
       " '13',\n",
       " 'efforts',\n",
       " 'dollar',\n",
       " 'miles',\n",
       " 'included',\n",
       " 'radio',\n",
       " 'live',\n",
       " 'form',\n",
       " 'david',\n",
       " 'african',\n",
       " 'increase',\n",
       " 'reports',\n",
       " 'sent',\n",
       " 'fourth',\n",
       " 'always',\n",
       " 'king',\n",
       " '50',\n",
       " 'tax',\n",
       " 'taiwan',\n",
       " 'britain',\n",
       " '16',\n",
       " 'playing',\n",
       " 'title',\n",
       " 'middle',\n",
       " 'meet',\n",
       " 'global',\n",
       " 'wife',\n",
       " '2009',\n",
       " 'position',\n",
       " 'located',\n",
       " 'clear',\n",
       " 'ahead',\n",
       " '2004',\n",
       " '2005',\n",
       " 'iraqi',\n",
       " 'english',\n",
       " 'result',\n",
       " 'release',\n",
       " 'violence',\n",
       " 'goal',\n",
       " 'project',\n",
       " 'closed',\n",
       " 'border',\n",
       " 'body',\n",
       " 'soon',\n",
       " 'crisis',\n",
       " 'division',\n",
       " '&amp;',\n",
       " 'served',\n",
       " 'tour',\n",
       " 'hospital',\n",
       " 'kong',\n",
       " 'test',\n",
       " 'hong',\n",
       " 'u.n.',\n",
       " 'inc.',\n",
       " 'technology',\n",
       " 'believe',\n",
       " 'organization',\n",
       " 'published',\n",
       " 'weapons',\n",
       " 'agreed',\n",
       " 'why',\n",
       " 'nine',\n",
       " 'summer',\n",
       " 'wanted',\n",
       " 'republican',\n",
       " 'act',\n",
       " 'recently',\n",
       " 'texas',\n",
       " 'course',\n",
       " 'problem',\n",
       " 'senate',\n",
       " 'medical',\n",
       " 'un',\n",
       " 'done',\n",
       " 'reached',\n",
       " 'star',\n",
       " 'continued',\n",
       " 'investors',\n",
       " 'living',\n",
       " 'care',\n",
       " 'signed',\n",
       " '17',\n",
       " 'art',\n",
       " 'provide',\n",
       " 'worked',\n",
       " 'presidential',\n",
       " 'gold',\n",
       " 'obama',\n",
       " 'morning',\n",
       " 'dead',\n",
       " 'opened',\n",
       " \"'ll\",\n",
       " 'event',\n",
       " 'previous',\n",
       " 'cost',\n",
       " 'instead',\n",
       " 'canada',\n",
       " 'band',\n",
       " 'teams',\n",
       " 'daily',\n",
       " '2001',\n",
       " 'available',\n",
       " 'drug',\n",
       " 'coming',\n",
       " '2003',\n",
       " 'investment',\n",
       " '’s',\n",
       " 'michael',\n",
       " 'civil',\n",
       " 'woman',\n",
       " 'training',\n",
       " 'appeared',\n",
       " '9',\n",
       " 'involved',\n",
       " 'indian',\n",
       " 'similar',\n",
       " 'situation',\n",
       " '24',\n",
       " 'los',\n",
       " 'running',\n",
       " 'fighting',\n",
       " 'mark',\n",
       " '40',\n",
       " 'trial',\n",
       " 'hold',\n",
       " 'australian',\n",
       " 'thought',\n",
       " '!',\n",
       " 'study',\n",
       " 'fall',\n",
       " 'mother',\n",
       " 'met',\n",
       " 'relations',\n",
       " 'anti',\n",
       " '2002',\n",
       " 'song',\n",
       " 'popular',\n",
       " 'base',\n",
       " 'tv',\n",
       " 'ground',\n",
       " 'markets',\n",
       " 'ii',\n",
       " 'newspaper',\n",
       " 'staff',\n",
       " 'saw',\n",
       " 'hand',\n",
       " 'hope',\n",
       " 'operations',\n",
       " 'pressure',\n",
       " 'americans',\n",
       " 'eastern',\n",
       " 'st.',\n",
       " 'legal',\n",
       " 'asia',\n",
       " 'budget',\n",
       " 'returned',\n",
       " 'considered',\n",
       " 'love',\n",
       " 'wrote',\n",
       " 'stop',\n",
       " 'fight',\n",
       " 'currently',\n",
       " 'charges',\n",
       " 'try',\n",
       " 'aid',\n",
       " 'ended',\n",
       " 'management',\n",
       " 'brought',\n",
       " 'cases',\n",
       " 'decided',\n",
       " 'failed',\n",
       " 'network',\n",
       " 'works',\n",
       " 'gas',\n",
       " 'turned',\n",
       " 'fact',\n",
       " 'vice',\n",
       " 'ca',\n",
       " 'mexico',\n",
       " 'trading',\n",
       " 'especially',\n",
       " 'reporters',\n",
       " 'afghanistan',\n",
       " 'common',\n",
       " 'looking',\n",
       " 'space',\n",
       " 'rates',\n",
       " 'manager',\n",
       " 'loss',\n",
       " '2011',\n",
       " 'justice',\n",
       " 'thousands',\n",
       " 'james',\n",
       " 'rather',\n",
       " 'fund',\n",
       " 'thing',\n",
       " 'republic',\n",
       " 'opening',\n",
       " 'accused',\n",
       " 'winning',\n",
       " 'scored',\n",
       " 'championship',\n",
       " 'example',\n",
       " 'getting',\n",
       " 'biggest',\n",
       " 'performance',\n",
       " 'sports',\n",
       " '1998',\n",
       " 'let',\n",
       " 'allowed',\n",
       " 'schools',\n",
       " 'means',\n",
       " 'turn',\n",
       " 'leave',\n",
       " 'no.',\n",
       " 'robert',\n",
       " 'personal',\n",
       " 'stocks',\n",
       " 'showed',\n",
       " 'light',\n",
       " 'arrested',\n",
       " 'person',\n",
       " 'either',\n",
       " 'offer',\n",
       " 'majority',\n",
       " 'battle',\n",
       " '19',\n",
       " 'class',\n",
       " 'evidence',\n",
       " 'makes',\n",
       " 'society',\n",
       " 'products',\n",
       " 'regional',\n",
       " 'needed',\n",
       " 'stage',\n",
       " 'am',\n",
       " 'doing',\n",
       " 'families',\n",
       " 'construction',\n",
       " 'various',\n",
       " '1996',\n",
       " 'sold',\n",
       " 'independent',\n",
       " 'kind',\n",
       " 'airport',\n",
       " 'paul',\n",
       " 'judge',\n",
       " 'internet',\n",
       " 'movement',\n",
       " 'room',\n",
       " 'followed',\n",
       " 'original',\n",
       " 'angeles',\n",
       " 'italy',\n",
       " '`',\n",
       " 'data',\n",
       " 'comes',\n",
       " 'parties',\n",
       " 'nothing',\n",
       " 'sea',\n",
       " 'bring',\n",
       " '2012',\n",
       " 'annual',\n",
       " 'officer',\n",
       " 'beijing',\n",
       " 'present',\n",
       " 'remain',\n",
       " 'nato',\n",
       " '1999',\n",
       " '22',\n",
       " 'remains',\n",
       " 'allow',\n",
       " 'florida',\n",
       " 'computer',\n",
       " '21',\n",
       " 'contract',\n",
       " 'coast',\n",
       " 'created',\n",
       " 'demand',\n",
       " 'operation',\n",
       " 'events',\n",
       " 'islamic',\n",
       " 'beat',\n",
       " 'analysts',\n",
       " 'interview',\n",
       " 'helped',\n",
       " 'child',\n",
       " 'probably',\n",
       " 'spent',\n",
       " 'asian',\n",
       " 'effort',\n",
       " 'cooperation',\n",
       " 'shows',\n",
       " 'calls',\n",
       " 'investigation',\n",
       " 'lives',\n",
       " 'video',\n",
       " 'yen',\n",
       " 'runs',\n",
       " 'tried',\n",
       " 'bad',\n",
       " 'described',\n",
       " '1994',\n",
       " 'toward',\n",
       " 'written',\n",
       " 'throughout',\n",
       " 'established',\n",
       " 'mission',\n",
       " 'associated',\n",
       " 'buy',\n",
       " 'growing',\n",
       " 'green',\n",
       " 'forward',\n",
       " 'competition',\n",
       " 'poor',\n",
       " 'latest',\n",
       " 'banks',\n",
       " 'question',\n",
       " '1997',\n",
       " 'prison',\n",
       " 'feel',\n",
       " 'attention',\n",
       " ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating glove to then use for overlapping with our dataset\n",
    "import torchtext\n",
    "\n",
    "#glove is a pre-trained library of vocabulary that has every word given thier corresponding identity number\n",
    "glove = torchtext.vocab.GloVe(name='6B',dim=50)\n",
    "glove.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "emotional-webmaster",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denylson\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Denylson\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.read_csv('./labeled_data.csv')\n",
    "dataframe = dataframe[['class', 'tweet']]\n",
    "dataframe = dataframe.replace([0,1,2], ['Hate Speech', 'Offensive Language', 'Other'])\n",
    "ps = PorterStemmer()\n",
    "lamatizer = WordNetLemmatizer()\n",
    "\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "dataframe = dataframe.apply(lambda x: x.astype(str).str.lower())\n",
    "dataframe.tweet = dataframe.tweet.str.replace('[^\\s\\w]','')\n",
    "dataframe.tweet = dataframe.tweet.str.replace('[^\\s\\w]','')\n",
    "dataframe.tweet = dataframe.tweet.str.replace('rt', '')\n",
    "dataframe['tweet_token'] = dataframe['tweet'].apply(lambda x: word_tokenize(x))\n",
    "# dataframe['tweet_recon'] = dataframe['tweet_token'].apply(lambda x: list(ps.stem(i) for i in x))\n",
    "# dataframe['tweet_recon'] = dataframe['tweet_recon'].apply(lambda x: ' '.join(list(i for i in x if i not in stops)))\n",
    "# tweet_tokenizer = Tokenizer(num_words = 4500, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower = True, split = ' ') \n",
    "# tweet_tokenizer.fit_on_texts(texts = dataframe['tweet_token'])\n",
    "\n",
    "# dataframe['tweet_token'] = tweet_tokenizer.texts_to_sequences(texts = dataframe['tweet_token'])\n",
    "\n",
    "dataframe.to_csv('./new_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "exotic-attraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "class Merger():\n",
    "    \n",
    "    def __init__(self, csv_path, max_length):\n",
    "        self.dataframe = pd.read_csv(csv_path)\n",
    "        self.max_length = max_length\n",
    "        self.label_dict = {\n",
    "            \"hate speech\" : 0,\n",
    "            \"offensive language\" : 1,\n",
    "            \"other\": 2\n",
    "        }\n",
    "        self.dataframe['tweet_token'] = self.dataframe['tweet'].apply(lambda x: word_tokenize(x))\n",
    "        \n",
    "        all_mentioned_words = []\n",
    "        for words in dataframe['tweet_token']:\n",
    "            all_mentioned_words += words\n",
    "        frequency = Counter(all_mentioned_words)\n",
    "        self.vocab = torchtext.vocab.Vocab(counter = frequency, min_freq = 25, vectors = glove)\n",
    "        \n",
    "        \n",
    "#         print(self.dataframe.head())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe['tweet'])\n",
    "    \n",
    "    def back_to_text(self, tokens):\n",
    "        text = ''\n",
    "        for tok in tokens:\n",
    "            text += self.vocab.itos[tok] + \" \"\n",
    "        return text\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        label = self.label_dict[self.dataframe['class'][index]]\n",
    "        label = torch.tensor(label)\n",
    "        int_tokens = []\n",
    "        tweet_tokens = self.dataframe['tweet_token'][index]\n",
    "        for token in tweet_tokens:\n",
    "            int_tokens.append(self.vocab[token])\n",
    "        if(len(int_tokens) < self.max_length):\n",
    "            num_to_pad = self.max_length - len(int_tokens)\n",
    "            int_tokens += [0] * num_to_pad\n",
    "        else:\n",
    "            int_tokens = int_tokens[:self.max_length]\n",
    "        int_tokens = torch.tensor(int_tokens)\n",
    "        return(int_tokens, label)\n",
    "        \n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "piano-interest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24783"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Merger( './new_data.csv', 50)\n",
    "len(dataset)\n",
    "pytorch.dataset.subset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "southeast-iceland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "indices_list = list(range(0, 24783))\n",
    "train_amount = int(0.8* len(dataset))\n",
    "train_indices = list(range(0, train_amount))\n",
    "test_indices = list(range(train_amount, len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "conscious-birthday",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "test_dataset = Subset(dataset, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "lyric-proportion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x206f8a75688>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 32, shuffle = True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = 32)\n",
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "checked-imagination",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 50]), torch.Size([32]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_data, batched_labels = next(iter(train_dataloader))\n",
    "batched_data.shape, batched_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "chicken-uganda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLP_model(nn.Module):\n",
    "    def __init__(self, num_words, emb_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_words = num_words\n",
    "        self.emb_size = emb_size\n",
    "        self.emb = nn.Embedding(self.num_words, self.emb_size)\n",
    "        self.emb.from_pretrained(vocab.vectors)\n",
    "        self.lstm = nn.LSTM(input_size = emb_size, hidden_size = 32, batch_first = True, num_layers = 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lin = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def forward(self, batch_data):\n",
    "        token_embs = self.emb(batch_data)\n",
    "        outputs, (h_n, c_n) = self.lstm(token_embs)\n",
    "        \n",
    "        last_hidden_state = h_n\n",
    "        last_hidden_state = last_hidden_state.permute(1, 0, 2)\n",
    "        last_hidden_state = last_hidden_state.flatten(start_dim = 1)\n",
    "\n",
    "        last_hidden_state = self.relu(last_hidden_state)\n",
    "        logits = self.lin(last_hidden_state)\n",
    "        \n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "monthly-refund",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NLP_model(\n",
       "  (emb): Embedding(1183, 50)\n",
       "  (lstm): LSTM(50, 32, num_layers=2, batch_first=True)\n",
       "  (relu): ReLU()\n",
       "  (lin): Linear(in_features=64, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NLP_model(num_words = len(vocab), emb_size = 50, num_classes = 3)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "growing-intellectual",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 50])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "greatest-green",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(batched_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dental-semiconductor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.01\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import optim\n",
    "opt = optim.Adam(model.parameters(), lr=0.01)\n",
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "shared-anatomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bulgarian-choir",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2313, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss_func(preds, batched_labels)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "extraordinary-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "opt.step()\n",
    "opt.zero_grad()\n",
    "#backwards, opt.step, opt.gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "growing-rehabilitation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0296, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model(batched_data)\n",
    "loss_func(preds, batched_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "smart-richmond",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "heated-assistant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "falling-christmas",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_acc(preds, batched_labels):\n",
    "    predicted_classes = torch.softmax(preds, dim = 1).argmax(dim = 1)\n",
    "\n",
    "    num_correct = (predicted_classes == batched_labels).sum()\n",
    "\n",
    "    acc = num_correct/len(batched_labels)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "reliable-guarantee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Train: loss : 0.7552304863929749, accuracy: 0.6875\n",
      "Train: loss : 0.7934530973434448, accuracy: 0.71875\n",
      "Train: loss : 0.8785288333892822, accuracy: 0.6875\n",
      "Train: loss : 0.49955829977989197, accuracy: 0.875\n",
      "Train: loss : 0.7573117613792419, accuracy: 0.75\n",
      "Train: loss : 0.8236463069915771, accuracy: 0.6875\n",
      "Train: loss : 0.6129195094108582, accuracy: 0.8125\n",
      "Train: loss : 0.8169825077056885, accuracy: 0.6875\n",
      "Train: loss : 0.5343446135520935, accuracy: 0.8125\n",
      "Train: loss : 0.5847054719924927, accuracy: 0.78125\n",
      "Train: loss : 0.7786131501197815, accuracy: 0.71875\n",
      "Train: loss : 0.9142997860908508, accuracy: 0.65625\n",
      "Train: loss : 0.6334542036056519, accuracy: 0.78125\n",
      "Test: loss : 0.654453456401825, accuracy: 0.9444444179534912\n",
      "Test: loss : 0.7114994525909424, accuracy: 0.9444444179534912\n",
      "Test: loss : 0.5666468739509583, accuracy: 0.9444444179534912\n",
      "Test: loss : 0.5547423958778381, accuracy: 0.9444444179534912\n",
      "--------------------------------------------------\n",
      "Train: loss : 0.8231151103973389, accuracy: 0.6875\n",
      "Train: loss : 0.6332626938819885, accuracy: 0.78125\n",
      "Train: loss : 0.6518542766571045, accuracy: 0.78125\n",
      "Train: loss : 0.5363319516181946, accuracy: 0.84375\n",
      "Train: loss : 0.703533947467804, accuracy: 0.75\n",
      "Train: loss : 0.5787954330444336, accuracy: 0.8125\n",
      "Train: loss : 0.9839769601821899, accuracy: 0.625\n",
      "Train: loss : 0.5787360668182373, accuracy: 0.8125\n",
      "Train: loss : 0.8356996178627014, accuracy: 0.65625\n",
      "Train: loss : 0.7556335926055908, accuracy: 0.6875\n",
      "Train: loss : 0.6803206205368042, accuracy: 0.75\n",
      "Train: loss : 0.5262563228607178, accuracy: 0.875\n",
      "Train: loss : 0.9573977589607239, accuracy: 0.65625\n",
      "Test: loss : 0.6837992072105408, accuracy: 0.8333333134651184\n",
      "Test: loss : 0.7072134613990784, accuracy: 0.8333333134651184\n",
      "Test: loss : 0.5221619009971619, accuracy: 0.8333333134651184\n",
      "Test: loss : 0.5352182388305664, accuracy: 0.8333333134651184\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"-\" * 50)\n",
    "    for i, (batched_data, batched_labels) in enumerate(train_dataloader):\n",
    "        preds = model(batched_data)\n",
    "        loss = loss_func(preds, batched_labels)\n",
    "        accuracy = cal_acc(preds, batched_labels)\n",
    "        if (i % 50 == 0):\n",
    "            print(\"Train: loss : {0}, accuracy: {1}\".format(loss, accuracy))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    for i, (batched_data, batched_labels) in enumerate(test_dataloader):\n",
    "        preds = model(batched_data)\n",
    "        loss = loss_func(preds, batched_labels)\n",
    "        if (i % 50 == 0):\n",
    "            print(\"Test: loss : {0}, accuracy: {1}\".format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "joint-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model.state_dict()\n",
    "torch.save(params, 'my_model_weights.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-student",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_loaded = torch.load('my_model_weights.pt')\n",
    "model2.load_state_dict(params_loaded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
